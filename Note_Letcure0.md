# Note_Letcure0

**Summary**: Trying to understand how computers work in human language

- **How do computers calculate?**
  - Binary (v.s human calculating in decimal), but the logic is similar.
    - Example: Instead of having three blubs representing 0-3, 3 bits could represent 0-7 (2^3) 
    - *Max utility! Efficiency of using space*
  - Computers use these digits/transistors (1byte = 8bits) to represent multi-media
    - Example: ASCII, Unicode, RGB... 
    - *But the representations are constantly __evolving__, just add more sets of bits!*
  
- **Input -> algorithm -> Output**
  - Introduction of dividing and conquering -> log2n
  
- **Important Principle**
  - Digitalizing/Standardization
  - Abstraction
  - Evolving, step by step
